<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Knn on 周森标博客</title>
    <link>http://senbiao.org/tags/knn/</link>
    <description>Recent content in Knn on 周森标博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Mar 2018 14:38:50 +0800</lastBuildDate>
    <atom:link href="http://senbiao.org/tags/knn/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>K-近邻算法学习笔记</title>
      <link>http://senbiao.org/post/k-nearest-neighbors/</link>
      <pubDate>Mon, 19 Mar 2018 14:38:50 +0800</pubDate>
      
      <guid>http://senbiao.org/post/k-nearest-neighbors/</guid>
      <description>k-近邻算法，目的就是找到新数据的前k个邻居，然后根据邻居的分类来确定该数据的分类。 所谓邻居，就是距离近的。因此需要一个“距离度量”，以2个特征的样本为例，也就是在2维实数向量空间，可以使用两点距离公式计算距离： $$ \sqrt{(x1-x2)^2+(y1-y2)^2} $$ k-近邻算法步骤如下： 计算已知类别数据集中的点与当前点之间的距离； 按照距离递增次序排序； 选取与当前点距离最小的k个点； 确定前k个点所在类别的出现频率； 返回前k个点所出现频率最高的类别作为当前点的预测分类。 比如，现在我这个k值取3，那么在电影例子中，按距离依次排序的三个点分别是动作片(108,5)、动作片(115,8)、爱情片(5,89)。 在这三个点中，动作片出现的频率为三分之二，爱情片出现的频率为三分之一，所以该红色圆点标记的电影为动作片。 这个判别过程就是k-近邻算法。 from：http://cuijiahua.com/blog/2017/11/ml_1_knn.html</description>
    </item>
    
  </channel>
</rss>
